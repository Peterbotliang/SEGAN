{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from utils import emphasis\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN\n",
    "\n",
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "class SubPixel1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, r=2):\n",
    "        super(SubPixel1D, self).__init__()\n",
    "        self.r = r\n",
    "    def call(self, I):\n",
    "        \"\"\"One-dimensional subpixel upsampling layer\n",
    "        Calls a tensorflow function that directly implements this functionality.\n",
    "         We assume input has dim (batch, width, r)\n",
    "        \"\"\"\n",
    "\n",
    "        X = tf.transpose(I, [2,1,0]) # (r, w, b)\n",
    "        X = tf.batch_to_space_nd(X, [self.r], [[0,0]]) # (1, r*w, b)\n",
    "        X = tf.transpose(X, [2,1,0])\n",
    "        return X\n",
    "\n",
    "noisy = tf.keras.layers.Input(shape=(4096, 1))\n",
    "clean = tf.keras.layers.Input(shape=(4096, 1))\n",
    "x_input = noisy\n",
    "x = x_input\n",
    "\n",
    "# B = 8\n",
    "# n_filters = [128, 256, 512, 512, 512, 512, 512, 512]\n",
    "# kernel_sizes = [65, 33, 17, 9, 9, 9, 9, 9]\n",
    "\n",
    "B = 4\n",
    "n_filters = [128, 256, 512, 512]\n",
    "kernel_sizes = [65, 33, 17, 9]\n",
    "\n",
    "# B = 1\n",
    "# n_filters = [128]\n",
    "# kernel_sizes = [65]\n",
    "\n",
    "# Downsampling Layers\n",
    "encoder_features = []\n",
    "for k, n_filter, kernel_size in zip(range(B), n_filters, kernel_sizes):\n",
    "    x = tf.keras.layers.Conv1D(filters = n_filter,\n",
    "                               kernel_size = kernel_size,\n",
    "                               strides = 2,\n",
    "                               padding = 'same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    encoder_features.append(x)\n",
    "    \n",
    "# Bottleneck Layer\n",
    "x = tf.keras.layers.Conv1D(filters = n_filters[-1],\n",
    "                           kernel_size = kernel_sizes[-1],\n",
    "                           strides = 2,\n",
    "                           padding = 'same')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "x = tf.keras.layers.PReLU()(x)\n",
    "\n",
    "# Upsampling Layer\n",
    "for k, n_filter, kernel_size, enc in reversed(list(zip(range(B), \n",
    "                                                  n_filters, \n",
    "                                                  kernel_sizes, \n",
    "                                                  encoder_features))):\n",
    "    x = tf.keras.layers.Conv1D(filters = n_filter,\n",
    "                               kernel_size = kernel_size,\n",
    "                               strides = 1,\n",
    "                               padding = 'same')(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = SubPixel1D()(x)\n",
    "    x = tf.keras.layers.Concatenate(axis=2)([x, enc])\n",
    "\n",
    "# Final Conv Layer\n",
    "x = tf.keras.layers.Conv1D(filters = 2,\n",
    "                           kernel_size = 9,\n",
    "                           strides = 1,\n",
    "                           padding = 'same')(x)\n",
    "x = SubPixel1D()(x)\n",
    "x_final = tf.keras.layers.Add()([x, x_input])    \n",
    "G = tf.keras.models.Model(inputs = [noisy], outputs = [x_final])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.load_weights('./model/weights.hdf5')\n",
    "optim = tf.keras.optimizers.Adam(lr=1e-4)\n",
    "def G_loss(true, fake):\n",
    "    return 1 * K.sqrt(K.mean((fake - true) ** 2))\n",
    "\n",
    "G.compile(loss = G_loss,\n",
    "          optimizer = optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8325bde90516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                      \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                      \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                      sample_rate)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-8325bde90516>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(file, window_size, stride, sample_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mby\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mpercent\u001b[0m \u001b[0moverlap\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mhop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sf' is not defined"
     ]
    }
   ],
   "source": [
    "window_size = 2 ** 12  # about 1 second of samples\n",
    "sample_rate = 16000\n",
    "stride = 0.5\n",
    "\n",
    "def predict(file, window_size, stride, sample_rate):\n",
    "    \"\"\"\n",
    "    Helper function for predicting the audio file\n",
    "    by window size and sample rate with [1-stride] percent overlap (default 50%).\n",
    "    \"\"\"\n",
    "    wav, sr = sf.read(file)\n",
    "    hop = int(window_size * stride)\n",
    "    result = np.zeros(wav.shape)\n",
    "    for end_idx in range(window_size, len(wav), hop):\n",
    "        start_idx = end_idx - window_size\n",
    "        noisy_test = wav[start_idx:end_idx]\n",
    "        noisy_test = noisy_test.reshape(1, -1, 1)\n",
    "        z_test = np.random.randn(1, 8, 1024)\n",
    "        clean_pred = G.predict((noisy_test, z_test), batch_size=1)\n",
    "        result[start_idx: end_idx] += clean_pred.reshape(-1)\n",
    "        \n",
    "    s = hop\n",
    "    e = end_idx - hop\n",
    "    result[s:e] *= 0.5\n",
    "    return result\n",
    "\n",
    "y_pred = predict('../dataset/timit_noisy/test/DR1_FAKS0_SA2.wav', \n",
    "                     window_size, \n",
    "                     stride, \n",
    "                     sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clean, fs = sf.read('../dataset/timit_clean/test/DR1_FAKS0_SA2.wav')\n",
    "librosa.display.waveplot(y_clean, sr = fs)\n",
    "\n",
    "D_clean = librosa.stft(y_clean)\n",
    "D_clean_db = librosa.amplitude_to_db(abs(D_clean))\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.specshow(D_clean_db, sr=fs, x_axis='time', y_axis='hz', cmap='jet')\n",
    "\n",
    "ipd.Audio(y_clean, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noisy, fs = sf.read('../dataset/timit_noisy/test/DR1_FAKS0_SA2.wav')\n",
    "librosa.display.waveplot(y_noisy, sr = fs)\n",
    "\n",
    "D_noisy = librosa.stft(y_noisy)\n",
    "D_noisy_db = librosa.amplitude_to_db(abs(D_noisy))\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.specshow(D_noisy_db, sr=fs, x_axis='time', y_axis='hz', cmap='jet')\n",
    "\n",
    "ipd.Audio(y_noisy, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(y_pred, sr = sample_rate)\n",
    "\n",
    "D_pred = librosa.stft(y_pred)\n",
    "D_pred_db = librosa.amplitude_to_db(abs(D_pred))\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.specshow(D_pred_db, sr=fs, x_axis='time', y_axis='hz', cmap='jet')\n",
    "\n",
    "ipd.Audio(y_pred, rate = sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
